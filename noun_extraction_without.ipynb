{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon=pd.read_csv(\"Eco_Friendly_Products_Test_Full.xlsx - Sheet1.csv\")\n",
    "amazon=pd.read_csv(\"Amazon Reviews Validation Data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The settings are perfect for all hair types</td>\n",
       "      <td>Adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with lots of settings</td>\n",
       "      <td>Adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heating element has died</td>\n",
       "      <td>Durability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also, the diffuser does not stay on at all.</td>\n",
       "      <td>Ease of Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it won't stay on it at all. Just flys off....</td>\n",
       "      <td>Ease of Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>top no longer stays on.</td>\n",
       "      <td>Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>unfortunately one of the lids does not fit at all</td>\n",
       "      <td>Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>cheap enough that if my husband loses one, we ...</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>economical price</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Also, there is no way to seal the drinking hol...</td>\n",
       "      <td>Safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews        Aspect\n",
       "0           The settings are perfect for all hair types  Adaptability\n",
       "1                                 with lots of settings  Adaptability\n",
       "2                              heating element has died    Durability\n",
       "3           Also, the diffuser does not stay on at all.   Ease of Use\n",
       "4     and it won't stay on it at all. Just flys off....   Ease of Use\n",
       "...                                                 ...           ...\n",
       "1176                            top no longer stays on.   Performance\n",
       "1177  unfortunately one of the lids does not fit at all   Performance\n",
       "1178  cheap enough that if my husband loses one, we ...         Price\n",
       "1179                                   economical price         Price\n",
       "1180  Also, there is no way to seal the drinking hol...        Safety\n",
       "\n",
       "[1181 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=amazon[\"Review\"]\n",
    "a=amazon[\"Reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=amazon[\"Aspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = q.str.split(',').explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = all_values.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_aspect=len(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_series = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             The settings are perfect for all hair types\n",
       "1                                   with lots of settings\n",
       "2                                heating element has died\n",
       "3             Also, the diffuser does not stay on at all.\n",
       "4       and it won't stay on it at all. Just flys off....\n",
       "                              ...                        \n",
       "1176                              top no longer stays on.\n",
       "1177    unfortunately one of the lids does not fit at all\n",
       "1178    cheap enough that if my husband loses one, we ...\n",
       "1179                                     economical price\n",
       "1180    Also, there is no way to seal the drinking hol...\n",
       "Name: Reviews, Length: 1181, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(words):\n",
    "    \"\"\"Extract and return nouns from a given list of words.\"\"\"\n",
    "    # Join the list of words into a sentence\n",
    "    # sentence = ' '.join(words)\n",
    "\n",
    "    # Tokenize and POS tag the words in the sentence\n",
    "    tokens = nltk.word_tokenize(words)\n",
    "    parts_of_speech = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Extract and return words tagged as NN, NNS, NNP, or NNPS\n",
    "    return [word for word, pos in parts_of_speech if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                 [settings, hair, types]\n",
      "1                                        [lots, settings]\n",
      "2                                               [element]\n",
      "3                                              [diffuser]\n",
      "4                                                  [Just]\n",
      "                              ...                        \n",
      "1176                                              [stays]\n",
      "1177                                               [lids]\n",
      "1178                                            [husband]\n",
      "1179                                              [price]\n",
      "1180    [way, drinking, hole, car, bump, liquid, cup, ...\n",
      "Name: Reviews, Length: 1181, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nouns = processed_series.apply(extract_nouns)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def extract_nouns_textblob(sentence):\n",
    "    \n",
    "    \"\"\"Extract and return nouns from a given sentence using TextBlob.\"\"\"\n",
    "    # sentence = ' '.join(sentence)\n",
    "    blob = TextBlob(sentence)\n",
    "    return [word for word, tag in blob.tags if tag in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                 [settings, hair, types]\n",
      "1                                        [lots, settings]\n",
      "2                                               [element]\n",
      "3                                              [diffuser]\n",
      "4                                                      []\n",
      "                              ...                        \n",
      "1176                                              [stays]\n",
      "1177                                               [lids]\n",
      "1178                                            [husband]\n",
      "1179                                              [price]\n",
      "1180    [way, drinking, hole, car, bump, liquid, cup, ...\n",
      "Name: Reviews, Length: 1181, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nouns_testblob = processed_series.apply(extract_nouns_textblob)\n",
    "print(nouns_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpt = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns_spacy(sentence):\n",
    "    \"\"\"Extract and return nouns from a given sentence using spaCy.\"\"\"\n",
    "    # sentence = ' '.join(sentence)\n",
    "    doc = nlpt(sentence)\n",
    "    return [token.text for token in doc if token.pos_ in [\"NOUN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 [settings, hair, types]\n",
       "1                                        [lots, settings]\n",
       "2                                      [heating, element]\n",
       "3                                              [diffuser]\n",
       "4                                                   [one]\n",
       "                              ...                        \n",
       "1176                                                [top]\n",
       "1177                                               [lids]\n",
       "1178                                            [husband]\n",
       "1179                                              [price]\n",
       "1180    [way, drinking, hole, car, bump, liquid, cup, ...\n",
       "Name: Reviews, Length: 1181, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = processed_series.apply(extract_nouns_spacy)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['way', 'drinking', 'hole', 'car', 'bump', 'liquid', 'cup', 'holder']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe Model\n",
      "Done. 400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    \"\"\"Load the GloVe model from a file.\"\"\"\n",
    "    print(\"Loading GloVe Model\")\n",
    "    with open(glove_file, 'r') as file:\n",
    "        model = {}\n",
    "        for line in file:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            model[word] = embedding\n",
    "        print(\"Done. {} words loaded!\".format(len(model)))\n",
    "    return model\n",
    "\n",
    "glove_model = load_glove_model(\"/Users/divyamsobti/Downloads/glove.6B/glove.6B.100d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_testblob=np.array(nouns_testblob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_spacy=np.array(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk=np.array(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns_tf(sentence):\n",
    "\n",
    "    # Tokenize and POS tag the words in the sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    parts_of_speech = nltk.pos_tag(tokens)\n",
    "    x=[word for word, pos in parts_of_speech if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "    x=\" \".join(x)\n",
    "    # Extract and return words tagged as NN, NNS, NNP, or NNPS\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_tf = processed_series.apply(extract_nouns_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                settings hair types\n",
       "1                                      lots settings\n",
       "2                                            element\n",
       "3                                           diffuser\n",
       "4                                               Just\n",
       "                            ...                     \n",
       "1176                                           stays\n",
       "1177                                            lids\n",
       "1178                                         husband\n",
       "1179                                           price\n",
       "1180    way drinking hole car bump liquid cup holder\n",
       "Name: Reviews, Length: 1181, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_nouns_textblob_tf(sentence):\n",
    "    \n",
    "    \"\"\"Extract and return nouns from a given sentence using TextBlob.\"\"\"\n",
    "    blob = TextBlob(sentence)\n",
    "    x=[word for word, tag in blob.tags if tag in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]]\n",
    "    x=\" \".join(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                settings hair types\n",
      "1                                      lots settings\n",
      "2                                            element\n",
      "3                                           diffuser\n",
      "4                                                   \n",
      "                            ...                     \n",
      "1176                                           stays\n",
      "1177                                            lids\n",
      "1178                                         husband\n",
      "1179                                           price\n",
      "1180    way drinking hole car bump liquid cup holder\n",
      "Name: Reviews, Length: 1181, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nouns_testblob_tf = processed_series.apply(extract_nouns_textblob_tf)\n",
    "print(nouns_testblob_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns_spacy_tf(sentence):\n",
    "    \"\"\"Extract and return nouns from a given sentence using spaCy.\"\"\"\n",
    "    doc = nlpt(sentence)\n",
    "    x=[token.text for token in doc if token.pos_ in [\"NOUN\"]]\n",
    "    x=\" \".join(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                settings hair types\n",
       "1                                      lots settings\n",
       "2                                    heating element\n",
       "3                                           diffuser\n",
       "4                                                one\n",
       "                            ...                     \n",
       "1176                                             top\n",
       "1177                                            lids\n",
       "1178                                         husband\n",
       "1179                                           price\n",
       "1180    way drinking hole car bump liquid cup holder\n",
       "Name: Reviews, Length: 1181, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tf = processed_series.apply(extract_nouns_spacy_tf)\n",
    "doc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert text to numerical vectors using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "nltk = vectorizer.fit_transform(nouns_tf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_=vectorizer.fit_transform(doc_tf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob_=vectorizer.fit_transform(nouns_testblob_tf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(word_list, model, vector_size=100):\n",
    "    \"\"\"Generate a sentence vector by averaging the word vectors.\"\"\"\n",
    "    word_vectors = [model[word] for word in word_list if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors_testblob = np.array([sentence_vector(sentence, glove_model) for sentence in sentences_testblob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors_spacy = np.array([sentence_vector(sentence, glove_model) for sentence in sentences_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors_nltk = np.array([sentence_vector(sentence, glove_model) for sentence in sentences_nltk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for 12 aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = len_aspect  # Example number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "num_clusters = len_aspect  # Example number of clusters\n",
    "kmeans_textblob = KMeans(n_clusters=num_clusters)\n",
    "kmeans_textblob.fit(sentence_vectors_testblob)\n",
    "labels_textblob = kmeans_textblob.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "kmeans_spacy = KMeans(n_clusters=num_clusters)\n",
    "kmeans_spacy.fit(sentence_vectors_spacy)\n",
    "labels_spacy = kmeans_spacy.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "kmeans_nltk = KMeans(n_clusters=num_clusters)\n",
    "kmeans_nltk.fit(sentence_vectors_nltk)\n",
    "labels_nltk = kmeans_nltk.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblobl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Textblob)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_testblob)\n",
    "\n",
    "# 3D Scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Textblob)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Spacy)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_spacy)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Spacy)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(NLTK)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_nltk)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(NLTK)',\n",
    "                    scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                                 yaxis_title='t-SNE Dimension 2',\n",
    "                                 zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans with 6 aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 6 # Example number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_textblob = KMeans(n_clusters=num_clusters)\n",
    "kmeans_textblob.fit(sentence_vectors_testblob)\n",
    "labels_textblob = kmeans_textblob.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_spacy = KMeans(n_clusters=num_clusters)\n",
    "kmeans_spacy.fit(sentence_vectors_spacy)\n",
    "labels_spacy = kmeans_spacy.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_nltk = KMeans(n_clusters=num_clusters)\n",
    "kmeans_nltk.fit(sentence_vectors_nltk)\n",
    "labels_nltk = kmeans_nltk.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ploting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblobl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Textblob)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_testblob)\n",
    "\n",
    "# 3D Scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Textblob)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Spacy)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_spacy)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Spacy)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(NLTK)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_nltk)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(NLTK)',\n",
    "                    scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                                 yaxis_title='t-SNE Dimension 2',\n",
    "                                 zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_6 = GaussianMixture(n_components = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(sentence_vectors_nltk)\n",
    "labels_nltk = gmm.predict(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(sentence_vectors_spacy)\n",
    "labels_spacy = gmm.predict(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(sentence_vectors_testblob)\n",
    "labels_textblob = gmm.predict(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblobl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Textblob)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_testblob)\n",
    "\n",
    "# 3D Scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Textblob)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Spacy)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_spacy)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Spacy)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(NLTK)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_nltk)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(NLTK)',\n",
    "                    scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                                 yaxis_title='t-SNE Dimension 2',\n",
    "                                 zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_6.fit(sentence_vectors_nltk)\n",
    "labels_nltk = gmm_6.predict(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_6.fit(sentence_vectors_spacy)\n",
    "labels_spacy = gmm_6.predict(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_6.fit(sentence_vectors_testblob )\n",
    "labels_textblob = gmm_6.predict(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblobl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_testblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Textblob)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_testblob) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_testblob)\n",
    "\n",
    "# 3D Scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_textblob == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Textblob)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(Spacy)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_spacy) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_spacy)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_spacy == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(Spacy)',\n",
    "                  scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                             yaxis_title='t-SNE Dimension 2',\n",
    "                             zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_2d = tsne.fit_transform(sentence_vectors_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=reduced_vectors_2d[indices, 0],\n",
    "        y=reduced_vectors_2d[indices, 1],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i + 1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentence Clusters Visualized with t-SNE(NLTK)',\n",
    "    xaxis_title='t-SNE Dimension 1',\n",
    "    yaxis_title='t-SNE Dimension 2',\n",
    "    legend_title=\"Clusters\"\n",
    ")\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction for 3D visualization\n",
    "perplexity_value = min(30, len(sentence_vectors_nltk) - 1)\n",
    "tsne_3d = TSNE(n_components=3,perplexity=perplexity_value, random_state=0)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(sentence_vectors_nltk)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    indices = labels_nltk == i\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=reduced_vectors_3d[indices, 0],\n",
    "        y=reduced_vectors_3d[indices, 1],\n",
    "        z=reduced_vectors_3d[indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'Cluster {i+1}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='3D Sentence Clusters(NLTK)',\n",
    "                    scene=dict(xaxis_title='t-SNE Dimension 1',\n",
    "                                 yaxis_title='t-SNE Dimension 2',\n",
    "                                 zaxis_title='t-SNE Dimension 3'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Cluster\n",
      "0                               [settings, hair, types]        4\n",
      "1                                      [lots, settings]        0\n",
      "2                                    [heating, element]        4\n",
      "3                                            [diffuser]        3\n",
      "4                                                 [one]        2\n",
      "...                                                 ...      ...\n",
      "1176                                              [top]        2\n",
      "1177                                             [lids]        1\n",
      "1178                                          [husband]        2\n",
      "1179                                            [price]        5\n",
      "1180  [way, drinking, hole, car, bump, liquid, cup, ...        4\n",
      "\n",
      "[1181 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df_spacy = pd.DataFrame({\n",
    "    'Sentence': doc,\n",
    "    'Cluster': labels_spacy\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Cluster\n",
      "0                               [settings, hair, types]        4\n",
      "1                                      [lots, settings]        4\n",
      "2                                             [element]        1\n",
      "3                                            [diffuser]        2\n",
      "4                                                    []        2\n",
      "...                                                 ...      ...\n",
      "1176                                            [stays]        4\n",
      "1177                                             [lids]        3\n",
      "1178                                          [husband]        4\n",
      "1179                                            [price]        0\n",
      "1180  [way, drinking, hole, car, bump, liquid, cup, ...        4\n",
      "\n",
      "[1181 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df_textblob = pd.DataFrame({\n",
    "    'Sentence': sentences_testblob,\n",
    "    'Cluster': labels_textblob\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Cluster\n",
      "0                               [settings, hair, types]        4\n",
      "1                                      [lots, settings]        1\n",
      "2                                             [element]        1\n",
      "3                                            [diffuser]        3\n",
      "4                                                [Just]        3\n",
      "...                                                 ...      ...\n",
      "1176                                            [stays]        1\n",
      "1177                                             [lids]        0\n",
      "1178                                          [husband]        2\n",
      "1179                                            [price]        2\n",
      "1180  [way, drinking, hole, car, bump, liquid, cup, ...        1\n",
      "\n",
      "[1181 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df_nltk = pd.DataFrame({\n",
    "    'Sentence': sentences_nltk,\n",
    "    'Cluster': labels_nltk\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
